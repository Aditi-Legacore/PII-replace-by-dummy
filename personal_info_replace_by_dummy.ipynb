{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb38c54-83d1-4f37-a865-3ae4df60a9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing page 1\n",
      "✔ Final enforced replacement done for page 1\n",
      "\n",
      "Processing page 2\n",
      "✔ Final enforced replacement done for page 2\n",
      "\n",
      "Processing page 3\n",
      "✔ Final enforced replacement done for page 3\n",
      "\n",
      "Processing page 4\n",
      "✔ Final enforced replacement done for page 4\n",
      "\n",
      "Processing page 5\n",
      "✔ Final enforced replacement done for page 5\n",
      "\n",
      "Processing page 6\n",
      "✔ Final enforced replacement done for page 6\n",
      "\n",
      "Processing page 7\n",
      "✔ Final enforced replacement done for page 7\n",
      "\n",
      "Processing page 8\n",
      "✔ Final enforced replacement done for page 8\n",
      "\n",
      "Processing page 9\n",
      "✔ Final enforced replacement done for page 9\n",
      "\n",
      "Processing page 10\n",
      "✔ Final enforced replacement done for page 10\n",
      "\n",
      "Processing page 11\n",
      "✔ Final enforced replacement done for page 11\n",
      "\n",
      "Processing page 12\n",
      "✔ Final enforced replacement done for page 12\n",
      "\n",
      "Processing page 13\n",
      "✔ Final enforced replacement done for page 13\n",
      "\n",
      "Processing page 14\n",
      "✔ Final enforced replacement done for page 14\n",
      "\n",
      "Processing page 15\n",
      "✔ Final enforced replacement done for page 15\n",
      "\n",
      "Processing page 16\n",
      "✔ Final enforced replacement done for page 16\n",
      "\n",
      "Processing page 17\n",
      "✔ Final enforced replacement done for page 17\n",
      "\n",
      "Processing page 18\n",
      "✔ Final enforced replacement done for page 18\n",
      "\n",
      "Processing page 19\n",
      "✔ Final enforced replacement done for page 19\n",
      "\n",
      "Processing page 20\n",
      "✔ Final enforced replacement done for page 20\n",
      "\n",
      "Processing page 21\n",
      "✔ Final enforced replacement done for page 21\n",
      "\n",
      "Processing page 22\n",
      "✔ Final enforced replacement done for page 22\n",
      "\n",
      "Processing page 23\n",
      "✔ Final enforced replacement done for page 23\n",
      "\n",
      "Processing page 24\n",
      "✔ Final enforced replacement done for page 24\n",
      "\n",
      "Processing page 25\n",
      "✔ Final enforced replacement done for page 25\n",
      "\n",
      "Processing page 26\n",
      "✔ Final enforced replacement done for page 26\n",
      "\n",
      "Processing page 27\n",
      "✔ Final enforced replacement done for page 27\n",
      "\n",
      "Processing page 28\n",
      "✔ Final enforced replacement done for page 28\n",
      "\n",
      "Processing page 29\n",
      "✔ Final enforced replacement done for page 29\n",
      "\n",
      "Processing page 30\n",
      "✔ Final enforced replacement done for page 30\n",
      "\n",
      "Processing page 31\n",
      "✔ Final enforced replacement done for page 31\n",
      "\n",
      "Processing page 32\n",
      "✔ Final enforced replacement done for page 32\n",
      "\n",
      "Processing page 33\n",
      "✔ Final enforced replacement done for page 33\n",
      "\n",
      "Processing page 34\n",
      "✔ Final enforced replacement done for page 34\n",
      "\n",
      "Processing page 35\n",
      "✔ Final enforced replacement done for page 35\n",
      "\n",
      "✅ PIPELINE COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import fitz\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "import random\n",
    "\n",
    "# -------------------------------------------------\n",
    "# TESSERACT PATH (WINDOWS)\n",
    "# -------------------------------------------------\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CLEAN TEXT\n",
    "# -------------------------------------------------\n",
    "def clean(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# JSON HELPERS\n",
    "# -------------------------------------------------\n",
    "def load_json(path, default=None):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return default if default is not None else {}\n",
    "\n",
    "def save_json(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# OCR PAGE\n",
    "# -------------------------------------------------\n",
    "def extract_text_from_page(pdf_path, page_index):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_index]\n",
    "        img = page.to_image(resolution=300)\n",
    "        return clean(pytesseract.image_to_string(img.original))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PICK DUMMY VALUE\n",
    "# -------------------------------------------------\n",
    "def pick_dummy(field, dummy_pool, used_dummies):\n",
    "    options = dummy_pool.get(field, [])\n",
    "    if not options:\n",
    "        return \"REDACTED\"\n",
    "\n",
    "    unused = [o for o in options if o not in used_dummies]\n",
    "    return random.choice(unused if unused else options)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# UPDATE MASTER + CREATE REPLACE_PAGE_N\n",
    "# -------------------------------------------------\n",
    "def build_replace_page(page_no, extracted_pii, dummy_pool, master_pii):\n",
    "    page_key = f\"page_{page_no}\"\n",
    "    replace_page = {}\n",
    "\n",
    "    used_dummies = {\n",
    "        v[\"dummy\"]\n",
    "        for p in master_pii.values()\n",
    "        for v in p.values()\n",
    "    }\n",
    "\n",
    "    for field, original in extracted_pii.items():\n",
    "        dummy = None\n",
    "\n",
    "        # reuse existing dummy if original already mapped\n",
    "        for page in master_pii.values():\n",
    "            for entry in page.values():\n",
    "                if entry[\"original\"] == original:\n",
    "                    dummy = entry[\"dummy\"]\n",
    "                    break\n",
    "            if dummy:\n",
    "                break\n",
    "\n",
    "        if not dummy:\n",
    "            dummy = pick_dummy(field, dummy_pool, used_dummies)\n",
    "            used_dummies.add(dummy)\n",
    "\n",
    "        replace_page[field] = {\n",
    "            \"original\": original,\n",
    "            \"dummy\": dummy\n",
    "        }\n",
    "\n",
    "    master_pii[page_key] = replace_page\n",
    "    return replace_page\n",
    "\n",
    "# -------------------------------------------------\n",
    "# SAFE REPLACEMENT (EMBEDDED STRINGS OK)\n",
    "# -------------------------------------------------\n",
    "def replace_from_map(text, replace_map):\n",
    "    entries = sorted(\n",
    "        replace_map.values(),\n",
    "        key=lambda x: len(x[\"original\"]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for e in entries:\n",
    "        if not e[\"original\"].strip():\n",
    "            continue\n",
    "\n",
    "        text = re.sub(\n",
    "            re.escape(e[\"original\"]),\n",
    "            e[\"dummy\"],\n",
    "            text,\n",
    "            flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "    return text\n",
    "\n",
    "# -------------------------------------------------\n",
    "# SECOND PASS: STRICTLY USE replace_page_n.json\n",
    "# -------------------------------------------------\n",
    "def final_replace_using_replace_page(page_no, output_dir):\n",
    "    pii_path = os.path.join(output_dir, f\"pii_page_{page_no}.json\")\n",
    "    replace_path = os.path.join(output_dir, f\"replace_page_{page_no}.json\")\n",
    "    txt_path = os.path.join(output_dir, f\"page_{page_no}_sanitized.txt\")\n",
    "\n",
    "    if not (os.path.exists(pii_path)\n",
    "            and os.path.exists(replace_path)\n",
    "            and os.path.exists(txt_path)):\n",
    "        return\n",
    "\n",
    "    pii_values = load_json(pii_path)\n",
    "    replace_page = load_json(replace_path)\n",
    "\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    for value in pii_values.values():\n",
    "        for entry in replace_page.values():\n",
    "            if entry[\"original\"] == value:\n",
    "                text = re.sub(\n",
    "                    re.escape(value),\n",
    "                    entry[\"dummy\"],\n",
    "                    text,\n",
    "                    flags=re.IGNORECASE\n",
    "                )\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    print(f\"✔ Final enforced replacement done for page {page_no}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# MAIN PIPELINE\n",
    "# -------------------------------------------------\n",
    "def process_pdf(pdf_path, output_dir, dummy_file):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    dummy_pool = load_json(dummy_file)\n",
    "    master_path = os.path.join(output_dir, \"master_pii.json\")\n",
    "    master_pii = load_json(master_path, {})\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for i in range(len(doc)):\n",
    "        page_no = i + 1\n",
    "        print(f\"\\nProcessing page {page_no}\")\n",
    "\n",
    "        text = extract_text_from_page(pdf_path, i)\n",
    "\n",
    "        pii_path = os.path.join(output_dir, f\"pii_page_{page_no}.json\")\n",
    "        extracted_pii = load_json(pii_path)\n",
    "\n",
    "        if not extracted_pii:\n",
    "            print(\"⚠ No pii_page file\")\n",
    "            continue\n",
    "\n",
    "        # 1️⃣ Build replace_page_n.json + update master\n",
    "        replace_page = build_replace_page(\n",
    "            page_no,\n",
    "            extracted_pii,\n",
    "            dummy_pool,\n",
    "            master_pii\n",
    "        )\n",
    "\n",
    "        save_json(\n",
    "            os.path.join(output_dir, f\"replace_page_{page_no}.json\"),\n",
    "            replace_page\n",
    "        )\n",
    "        save_json(master_path, master_pii)\n",
    "\n",
    "        # 2️⃣ First sanitization\n",
    "        sanitized = replace_from_map(text, replace_page)\n",
    "        sanitized_path = os.path.join(\n",
    "            output_dir, f\"page_{page_no}_sanitized.txt\"\n",
    "        )\n",
    "\n",
    "        with open(sanitized_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sanitized)\n",
    "\n",
    "        # 3️⃣ Enforced second-pass replacement\n",
    "        final_replace_using_replace_page(page_no, output_dir)\n",
    "\n",
    "    print(\"\\n✅ PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN\n",
    "# -------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    process_pdf(\n",
    "        # pdf_path=r\"D:\\py-tesseract\\BF - James Freer\\Arranged Medical Records and Bills\\Medical Provider Records\\MR.pdf\",\n",
    "        pdf_path=r\"D:\\\\py-tesseract\\\\PII replace by dummy\\\\MR.pdf\",\n",
    "        output_dir=\"output\",\n",
    "        dummy_file=\"dummy.json\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
